image: registry.gitlab.com/fyjaan983/ci-cd-automation-through-jenkins/liquibase-psql:latest

stages:
  - docker_build_for_POSTGRES_LIQUIBASE
  - build_for_POSTGRESDB_connection
  - clone_the_masterDB_from_MAIN
  - test_clonedDB
  - deploy_to_UATPROD
  - rollback_to_restore_artifacts

# ---------------- DOCKER BUILD & PUSH ----------------
DOCKER_BUILD:
  stage: docker_build_for_POSTGRES_LIQUIBASE
  image: docker:24.0.5
  services:
    - docker:24.0.5-dind
  variables:
    DOCKER_HOST: tcp://docker:2375
    DOCKER_TLS_CERTDIR: ""
  before_script:
    - echo "$CI_REGISTRY_PASSWORD" | docker login -u "$CI_REGISTRY_USER" --password-stdin $CI_REGISTRY
  script: |
    echo "Building custom Liquibase+psql Docker image..."
    docker build -t $CI_REGISTRY_IMAGE/liquibase-psql:latest .
    echo "Pushing image to GitLab registry..."
    docker push $CI_REGISTRY_IMAGE/liquibase-psql:latest
  only:
    refs: [main]

# ---------------- BUILD STAGE ----------------
BUILD_JOB:
  stage: build_for_POSTGRESDB_connection
  image: $CI_REGISTRY_IMAGE/liquibase-psql:latest
  services:
    - name: postgres:15
      alias: db
  variables:
    POSTGRES_USER: postgres
    POSTGRES_PASSWORD: postgres
    POSTGRES_DB: postgres
  script: |
    echo "===== BUILD: validate changelog (Liquibase) ====="
    for i in $(seq 1 30); do
      psql -h db -U "$POSTGRES_USER" -d "$POSTGRES_DB" -c "SELECT 1" && break || (echo "Waiting for DB to be ready ($i)"; sleep 2)
    done
    liquibase --url="jdbc:postgresql://db:5432/$POSTGRES_DB" \
              --username="$POSTGRES_USER" \
              --password="$POSTGRES_PASSWORD" \
              --changeLogFile=changelog.xml validate
  artifacts:
    paths: [build_log.txt]
    expire_in: 1 week
  only:
    refs: [main]
#-----------------------------------------------------------------------------  
# Save a copy of the repo files after build
SAVE_GOOD_STATE:
  stage: build_for_POSTGRESDB_connection
  image: alpine:latest
  before_script:
    - apk add --no-cache rsync
  script:
    - echo "Saving current state of repository..."
    - mkdir backup_state
    - rsync -av --progress ./ ./backup_state --exclude backup_state
  artifacts:
    paths:
      - backup_state/
    expire_in: 1 week
  only:
    refs: [main]

# ---------------- CREATE TEMP CLONE DB (dump as artifact) ----------------
DB_CLONE:
  stage: clone_the_masterDB_from_MAIN
  image: $CI_REGISTRY_IMAGE/liquibase-psql:latest
  services:
    - name: postgres:15
      alias: db
  variables:
    POSTGRES_USER: postgres
    POSTGRES_PASSWORD: postgres
    POSTGRES_DB: postgres
  before_script: |
    export PGPASSWORD="$POSTGRES_PASSWORD"
    for i in $(seq 1 30); do
      psql -h db -U "$POSTGRES_USER" -d "$POSTGRES_DB" -c "SELECT 1" && break || (echo "Waiting for DB to be ready ($i)"; sleep 2)
    done
  script: |
    set -e
    DBNAME="clone_${CI_COMMIT_SHORT_SHA}"
    echo "Creating temp DB: $DBNAME"
    psql -h db -U "$POSTGRES_USER" -d postgres -c "DROP DATABASE IF EXISTS \"$DBNAME\";"
    psql -h db -U "$POSTGRES_USER" -d postgres -c "CREATE DATABASE \"$DBNAME\";"

    echo "Applying schema/data from repo into $DBNAME ..."
    if [ -f changelog.xml ]; then
      echo "Found changelog.xml -> applying via Liquibase"
      liquibase --url="jdbc:postgresql://db:5432/$DBNAME" \
                --username="$POSTGRES_USER" \
                --password="$POSTGRES_PASSWORD" \
                --changeLogFile=changelog.xml update
    else
      # Apply SQL files if present. Prefer ./sql/*.sql, else search current repo depth.
      if ls sql/*.sql >/dev/null 2>&1; then
        echo "Applying sql/*.sql in sorted order"
        for f in $(ls sql/*.sql | sort); do
          echo "Applying $f"
          psql -v ON_ERROR_STOP=1 -h db -U "$POSTGRES_USER" -d "$DBNAME" -f "$f"
        done
      elif ls *.sql >/dev/null 2>&1 || find . -maxdepth 2 -type f -name "*.sql" | grep -q .; then
        echo "Applying all *.sql found at repo root (depth<=2) in sorted order"
        find . -maxdepth 2 -type f -name "*.sql" | sort | while read -r f; do
          echo "Applying $f"
          psql -v ON_ERROR_STOP=1 -h db -U "$POSTGRES_USER" -d "$DBNAME" -f "$f"
        done
      else
        echo "ERROR: No changelog.xml and no .sql files found to build the DB."
        exit 1
      fi
    fi

    echo "Dumping $DBNAME to artifact clone.dump (custom format)"
    pg_dump -h db -U "$POSTGRES_USER" -d "$DBNAME" -Fc -f clone.dump

    # Save DBNAME for later jobs
    printf "DBNAME=%s\n" "$DBNAME" > clone.env
  artifacts:
    reports:
      dotenv: clone.env
    paths:
      - clone.dump
      - clone.env
    expire_in: 2 hours
  only:
    refs: [main]

# ---------------- TEST JOB (recreate DB from dump, then validate) ----------------
TEST_JOB:
  stage: test_clonedDB
  image: alpine:latest
  script:
    #  Unit Tests for employee and department tables
    - echo "Checking Employees.sql for salary < 10000"
    - |
      if grep -i "insert" Employees.sql | \
        awk -F'[(), ]+' '{for(i=1;i<=NF;i++) if(tolower($i)=="values"){print $(i+4)}}' | \
        awk '{if($1<10000){print "Found salary < 10000: "$1; exit 1}}'; then
        echo "All salaries are above threshold limit"
      else
        echo "Fail: Employees.sql check failed"
        touch test_fail_employees
      fi

    - echo "Checking Department.sql for duplicate DEPT_ID"
    - |
      if grep -i "insert" Department.sql | \
        awk -F'[(), ]+' '{for(i=1;i<=NF;i++) if(tolower($i)=="values"){print $(i+1)}}' | \
        sort | uniq -d | grep .; then
        echo "Duplicate DEPT_ID found"
        touch test_fail_department
      else
        echo "No duplicates"
      fi

      # Detect missing exception handling
      if ! grep -q "EXCEPTION" EMP_DEPT_pkb*.sql; then
        echo "No exception handling found"
        touch test_fail_plsql
      fi

      # Detect hardcoded passwords
      if grep -Ei "password|passwd|pwd" EMP_DEPT_pkb*.sql; then
        echo "Potential hardcoded password"
        touch test_fail_plsql
      fi

    # Fail if any tests failed
    - |
      if [ -f test_fail_employees ] || [ -f test_fail_department ] || [ -f test_fail_plsql ]; then
        echo "Static analysis failed"
        exit 1
      fi
  artifacts:
    paths:
      - test_fail_employees
      - test_fail_department
      - test_fail_plsql
    when: always
    expire_in: 48 hours
  only:
    refs: [main]

# ---------------- DEPLOY TO UAT (simulated) ----------------
DEPLOY_UAT:
  stage: deploy_to_UATPROD
  image: $CI_REGISTRY_IMAGE/liquibase-psql:latest
  services:
    - name: postgres:15
      alias: db
  variables:
    POSTGRES_USER: postgres
    POSTGRES_PASSWORD: postgres
  before_script: |
    export PGPASSWORD="$POSTGRES_PASSWORD"
    for i in $(seq 1 30); do
      psql -h db -U "$POSTGRES_USER" -d postgres -c "SELECT 1" && break || (echo "Waiting for DB to be ready ($i)"; sleep 2)
    done
  script: |
    echo "===== DEPLOY UAT (simulated) ====="
    exists=$(psql -h db -U "$POSTGRES_USER" -d postgres -tAc "SELECT 1 FROM pg_database WHERE datname='uatdb';")
    if [ "$exists" != "1" ]; then
      psql -h db -U "$POSTGRES_USER" -d postgres -c "CREATE DATABASE uatdb;"
    fi
    liquibase --url="jdbc:postgresql://db:5432/uatdb" \
              --username="$POSTGRES_USER" \
              --password="$POSTGRES_PASSWORD" \
              --changeLogFile=changelog.xml update
    echo "UAT deploy complete."
  when: manual
  environment:
    name: uat
  only:
    refs: [main]
# ---------------- DEPLOY TO PROD (simulated) ----------------
DEPLOY_PROD:
  stage: deploy_to_UATPROD
  image: $CI_REGISTRY_IMAGE/liquibase-psql:latest
  services:
    - name: postgres:15
      alias: db
  variables:
    POSTGRES_USER: postgres
    POSTGRES_PASSWORD: postgres
  before_script: |
    export PGPASSWORD="$POSTGRES_PASSWORD"
    for i in $(seq 1 30); do
      psql -h db -U "$POSTGRES_USER" -d postgres -c "SELECT 1" && break || (echo "Waiting for DB to be ready ($i)"; sleep 2)
    done
  script: |
    echo "===== DEPLOY PROD (simulated) ====="
    exists=$(psql -h db -U "$POSTGRES_USER" -d postgres -tAc "SELECT 1 FROM pg_database WHERE datname='proddb';")
    if [ "$exists" != "1" ]; then
      psql -h db -U "$POSTGRES_USER" -d postgres -c "CREATE DATABASE proddb;"
    fi
    liquibase --url="jdbc:postgresql://db:5432/proddb" \
              --username="$POSTGRES_USER" \
              --password="$POSTGRES_PASSWORD" \
              --changeLogFile=changelog.xml update
    echo "PROD deploy complete."
  when: manual
  environment:
    name: production
  only:
    refs: [main]
# ---------------- CLEANUP (mostly no-op; services are ephemeral) ----------------
ROLLBACK_CLONE:
  stage: rollback_to_restore_artifacts
  image: alpine:latest
  before_script:
     - apk add --no-cache rsync bash
  script:
    - echo "=== Starting rollback process (using artifacts) ==="
    - |
      if [ -f test_fail_employees ] || [ -f test_fail_department ]; then
        echo "Tests failed, restoring files from saved state..."
        rsync -av --progress ./backup_state/ ./ --exclude backup_state
        echo "Rollback completed (files restored locally)."
      else
        echo "No rollback needed, tests passed."
      fi
  artifacts:
    name: "rollback_result_$CI_PIPELINE_ID"
    paths:
      - .
    exclude:
      - backup_state/
      - .git/
    expire_in: 1 week
  needs:
    - job: SAVE_GOOD_STATE
      artifacts: true
    - job: TEST_JOB
      artifacts: true
  when: on_failure
  only:
    refs: [main]

    